{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4d957d",
   "metadata": {},
   "source": [
    "# TP2 - CLASE 3\n",
    "\n",
    "## 1. Medición de foco en toda la imagen\n",
    "\n",
    "### Objetivo:\n",
    "Implementar un detector de máximo enfoque sobre un video aplicando técnicas de análisis espectral similar al que utilizan las cámaras digitales modernas. El video a procesar será: **focus_video.mov**.\n",
    "\n",
    "Se debe implementar un algoritmo que dada una imagen, o región, calcule la métrica propuesta en el paper **\"Image Sharpness Measure for Blurred Images in Frequency Domain\"** y realizar tres experimentos:\n",
    "\n",
    "1. **Medición sobre todo el frame.**\n",
    "2. **Medición sobre una ROI ubicada en el centro del frame.** Área de la ROI = 5 o 10% del área total del frame.\n",
    "\n",
    "### Opcional:\n",
    "1. **Medición sobre una matriz de enfoque** compuesta por un arreglo de NxM elementos rectangulares equiespaciados. N y M son valores arbitrarios, probar con varios valores 3x3, 7x5, etc. (al menos 3)\n",
    "\n",
    "### Para cada experimento se debe presentar:\n",
    "- Una curva o varias curvas que muestren la evolución de la métrica frame a frame donde se vea claramente cuando el algoritmo detectó el punto de máximo enfoque.\n",
    "\n",
    "## 2. Cambiar la métrica de enfoque\n",
    "Eligiendo uno de los algoritmos explicados en el apéndice de: **\"Analysis of focus measure operators in shape from focus\"**.\n",
    "\n",
    "El algoritmo de detección a implementar debe detectar y devolver los puntos de máximo enfoque de manera automática.\n",
    "\n",
    "### Resultados esperados:\n",
    "- Matriz de enfoque superpuesta a uno de los frames del video\n",
    "- Gráfico de la métrica asociado al experimento\n",
    "\n",
    "### Puntos extra:\n",
    "Aplicar unsharp masking para expandir la zona de enfoque y recalcular la métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f689f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd18348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open video file and extract metadata\n",
    "video_path = \"data/focus_video.mov\"\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = frame_count / fps if fps > 0 else 0\n",
    "    \n",
    "    video_info = {\n",
    "        'frames': frame_count,\n",
    "        'resolution': f\"{width}x{height}\",\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'fps': fps,\n",
    "        'duration_seconds': duration,\n",
    "        'codec': int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    }\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    for key, value in video_info.items():\n",
    "        if key == 'codec':\n",
    "            codec_str = ''.join([chr((value >> 8 * i) & 0xFF) for i in range(4)])\n",
    "            print(f\"{key}: {codec_str}\")\n",
    "        elif key == 'duration_seconds':\n",
    "            print(f\"{key}: {value:.2f}\")\n",
    "        elif key == 'fps':\n",
    "            print(f\"{key}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "            \n",
    "else:\n",
    "    print(f\"Video file not found: {video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a video showing the Fourier transform of each frame\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "input_path = \"data/focus_video.mov\"\n",
    "output_path = \"outputs/fourier_transform_video.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "for i in range(frame_count):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    f_transform = np.fft.fft2(gray)\n",
    "    f_shift = np.fft.fftshift(f_transform)\n",
    "    magnitude_spectrum = np.log(np.abs(f_shift) + 1)\n",
    "    \n",
    "    magnitude_normalized = cv2.normalize(magnitude_spectrum, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    magnitude_bgr = cv2.cvtColor(magnitude_normalized, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    out.write(magnitude_bgr)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Fourier transform video saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb7e2c9",
   "metadata": {},
   "source": [
    "3. Proposed Algorithm for calculating Image Quality measure\n",
    "3.1 Algorithm for image quality measure\n",
    "Input: Image I of size M×N.\n",
    "Output: Image Quality measure (FM) where FM stands for Frequency Domain Image Blur Measure\n",
    "Step 1: Compute F which is the Fourier Transform representation of image I\n",
    "Step 2: Find Fc which is obtained by shifting the origin of F to centre.\n",
    "Step 3: Calculate AF = abs (Fc) where AF is the absolute value of the centered Fourier transform of image I.\n",
    "Step 4: Calculate M = max (AF) where M is the maximum value of the frequency component in F.\n",
    "Step 5: Calculate TH = the total number of pixels in F whose pixel value > thres, where thres = M/1000.\n",
    "Step 6: Calculate Image Quality measure (FM) from equation (1).\n",
    "FM = TH / (M * N) (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_quality(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    f_transform = np.fft.fft2(gray)\n",
    "    f_shift = np.fft.fftshift(f_transform)\n",
    "    magnitude_spectrum = np.abs(f_shift)\n",
    "    \n",
    "    M = np.max(magnitude_spectrum)\n",
    "    thres = M / 1000\n",
    "    TH = np.sum(magnitude_spectrum > thres)\n",
    "    N = image.shape[0] * image.shape[1]\n",
    "    \n",
    "    FM = TH / (M * N) if M * N != 0 else 0\n",
    "    return FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f7b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/focus_video.mov\"\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "quality_scores = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    quality = calculate_image_quality(frame)\n",
    "    quality_scores.append(quality)\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot quality scores over time\n",
    "max = np.argmax(quality_scores) if quality_scores else 0\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(quality_scores, marker='o')\n",
    "plt.axvline(x=max, color='r', linestyle='--', label=f'Max Quality Frame: {max}')\n",
    "plt.title('Image Quality Scores Over Time')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Quality Score (FM)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(f\"Max quality score: {quality_scores[max]:.6f} at frame {max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_quality_roi(image, porcentage_roi=0.05):\n",
    "    im=image.copy()\n",
    "    h, w, _ = im.shape\n",
    "    roi_h, roi_w = int(h * porcentage_roi), int(w * porcentage_roi)\n",
    "    start_h, start_w = (h - roi_h) // 2, (w - roi_w) // 2\n",
    "    roi = im[start_h:start_h + roi_h, start_w:start_w + roi_w]\n",
    "    FM=calculate_image_quality(roi)\n",
    "    \n",
    "    return FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/focus_video.mov\"\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "quality_scores_5p = []\n",
    "quality_scores_10p = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    quality_5p = calculate_image_quality_roi(frame, porcentage_roi=0.05)\n",
    "    quality_scores_5p.append(quality_5p)\n",
    "    quality_10p = calculate_image_quality_roi(frame, porcentage_roi=0.10)\n",
    "    quality_scores_10p.append(quality_10p)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot quality scores ROI over time and the max value\n",
    "max_5p = np.argmax(quality_scores_5p) if quality_scores_5p else 0\n",
    "max_10p = np.argmax(quality_scores_10p) if quality_scores_10p else 0\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(quality_scores_5p, marker='o', label='5% ROI')\n",
    "plt.plot(quality_scores_10p, marker='x', label='10% ROI')\n",
    "plt.axvline(x=max_5p, color='r', linestyle='--', label=f'Max 5% ROI, frame {max_5p}' if quality_scores_5p else '')\n",
    "plt.axvline(x=max_10p, color='g', linestyle='--', label=f'Max 10% ROI, frame {max_10p}' if quality_scores_10p else '')\n",
    "plt.title('Image Quality Scores Over Time (ROI)')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Quality Score (FM)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(f\"Max quality score (5% ROI): {quality_scores_5p[max_5p]:.6f} at frame {max_5p}\")\n",
    "print(f\"Max quality score (10% ROI): {quality_scores_10p[max_10p]:.6f} at frame {max_10p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the max quality frame for all the algorithms\n",
    "max = np.argmax(quality_scores) if quality_scores else 0\n",
    "max_5p = np.argmax(quality_scores_5p) if quality_scores_5p else 0\n",
    "max_10p = np.argmax(quality_scores_10p) if quality_scores_10p else 0\n",
    "input_path = \"data/focus_video.mov\"\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "quality_scores_5p = []\n",
    "quality_scores_10p = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) - 1 == max:\n",
    "        max_frame = frame.copy()\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) - 1 == max_5p:\n",
    "        max_frame_5p = frame.copy()\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) - 1 == max_10p:\n",
    "        max_frame_10p = frame.copy()\n",
    "cap.release()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(max_frame, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Max Quality Frame: {max}')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cv2.cvtColor(max_frame_5p, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Max 5% ROI Frame: {max_5p}')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(max_frame_10p, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Max 10% ROI Frame: {max_10p}')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_quality_matrix(image, matrix_size=(3, 3)):\n",
    "    rows, cols = matrix_size\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    cell_h = h // rows\n",
    "    cell_w = w // cols\n",
    "    \n",
    "    quality_matrix = np.zeros((rows, cols))\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            start_h = i * cell_h\n",
    "            end_h = start_h + cell_h if i < rows - 1 else h\n",
    "            start_w = j * cell_w\n",
    "            end_w = start_w + cell_w if j < cols - 1 else w\n",
    "            \n",
    "            cell = image[start_h:end_h, start_w:end_w]\n",
    "            quality_matrix[i, j] = calculate_image_quality(cell)\n",
    "    \n",
    "    return quality_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb294ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/focus_video.mov\"\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "matrix_sizes = [(3, 3), (5, 7), (7, 5)]\n",
    "quality_scores_matrix = {str(size): [] for size in matrix_sizes}\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    for matrix_size in matrix_sizes:\n",
    "        quality_matrix = calculate_image_quality_matrix(frame, matrix_size)\n",
    "        avg_quality = np.mean(quality_matrix)\n",
    "        quality_scores_matrix[str(matrix_size)].append(avg_quality)\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebcbc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for i, (matrix_size, scores) in enumerate(quality_scores_matrix.items()):\n",
    "    max_idx = np.argmax(scores) if scores else 0\n",
    "    plt.plot(scores, marker='o', label=f'Matrix {matrix_size}')\n",
    "    plt.axvline(x=max_idx, linestyle='--', alpha=0.7, label=f'Max {matrix_size}: frame {max_idx}')\n",
    "\n",
    "plt.title('Image Quality Scores Over Time (Matrix Focus)')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Average Quality Score (FM)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "for matrix_size, scores in quality_scores_matrix.items():\n",
    "    if scores:\n",
    "        max_idx = np.argmax(scores)\n",
    "        print(f\"Matrix {matrix_size} - Max quality: {scores[max_idx]:.6f} at frame {max_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02426a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_matrix_overlay(image, matrix_size, quality_matrix):\n",
    "    h, w = image.shape[:2]\n",
    "    rows, cols = matrix_size\n",
    "    cell_h = h // rows\n",
    "    cell_w = w // cols\n",
    "    \n",
    "    overlay = image.copy()\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            start_h = i * cell_h\n",
    "            end_h = start_h + cell_h\n",
    "            start_w = j * cell_w\n",
    "            end_w = start_w + cell_w\n",
    "            \n",
    "            if end_h > h:\n",
    "                end_h = h\n",
    "            if end_w > w:\n",
    "                end_w = w\n",
    "            \n",
    "            quality_val = quality_matrix[i, j]\n",
    "            max_quality = np.max(quality_matrix)\n",
    "            \n",
    "            intensity = int(255 * (quality_val / max_quality)) if max_quality > 0 else 0\n",
    "            color = (0, intensity, 255 - intensity)\n",
    "            \n",
    "            cv2.rectangle(overlay, (start_w, start_h), (end_w, end_h), color, 2)\n",
    "            cv2.putText(overlay, f'{quality_val:.3f}', (start_w + 5, start_h + 20), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    \n",
    "    return overlay\n",
    "\n",
    "best_score = 0\n",
    "best_matrix_size = None\n",
    "for matrix_key, scores in quality_scores_matrix.items():\n",
    "    if scores and np.max(scores) > best_score:\n",
    "        best_score = np.max(scores)\n",
    "        best_matrix_size = matrix_key\n",
    "\n",
    "best_frame_idx = np.argmax(quality_scores_matrix[best_matrix_size]) if best_matrix_size else 0\n",
    "\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, best_frame_idx)\n",
    "ret, best_frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    matrix_size = eval(best_matrix_size)\n",
    "    quality_matrix = calculate_image_quality_matrix(best_frame, matrix_size)\n",
    "    overlay_image = visualize_matrix_overlay(best_frame, matrix_size, quality_matrix)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(best_frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Best Quality Frame: {best_frame_idx}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(cv2.cvtColor(overlay_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Matrix Overlay {matrix_size}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(quality_matrix, cmap='hot', interpolation='nearest')\n",
    "    plt.title('Quality Matrix Heatmap')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
